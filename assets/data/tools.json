[{"name":"Hasher Matcher Action (HMA) by Meta","link":"https://github.com/facebook/ThreatExchange/tree/main/hasher-matcher-actioner","description":"hashing algorithm, matching function, and ability to hook into actions","category":"Hash Matching"},{"name":"PDQ by Meta","link":"https://github.com/facebook/ThreatExchange/tree/main/pdq","description":"perceptual hash algorithm for images","category":"Hash Matching"},{"name":"TMK by Meta","link":"https://github.com/facebook/ThreatExchange/tree/main/tmk","description":"visual similarity match for videos","category":"Hash Matching"},{"name":"VPDQ","link":"https://github.com/facebook/ThreatExchange/tree/main/vpdq","description":"visual similarity match for videos using PDQ algorithm","category":"Hash Matching"},{"name":"Hasher-Matcher-Actioner (CLIP demo)","link":"https://github.com/juanmrad/HMA-CLIP-demo","description":"HMA extension for CLIP as reference for adding other format extensins","category":"Hash Matching"},{"name":"Perception","link":"https://github.com/thorn-oss/perception","description":"provides a common wrapper around existing, popular perceptual hashes (such as those implemented by ImageHash)","category":"Hash Matching"},{"name":"Altitude by Jigsaw","link":"https://github.com/jigsaw-code/altitude","description":"web UI and hash matching for violent extremism and terrorism content","category":"Hash Matching"},{"name":"Lattice Extract by Adobe","link":"https://github.com/adobe/lattice_extract","description":"grid and lattice detection to guard against FP in hash matching","category":"Hash Matching"},{"name":"RocketChat CSAM","link":"https://github.com/prostasia/rocketchatcsam","description":"CSAM hash matching for RocketChat","category":"Hash Matching"},{"name":"MediaModeration (Wiki Extension)","link":"https://github.com/wikimedia/mediawiki-extensions-MediaModeration?tab=readme-ov-file","description":"CSAM hash matching for Wikimedia","category":"Hash Matching"},{"name":"OSmod by Jigsaw","link":"https://github.com/conversationai/conversationai-moderator","description":"toolkit of machine learning (ML) tools, models, and APIs that platforms can use to moderate content","category":"Classification"},{"name":"Perspective API by Jigsaw","link":"https://github.com/conversationai/perspectiveapi","description":"machine learning-powered tool that helps platforms detect and assess the toxicity of online conversations","category":"Classification"},{"name":"Presidio by Microsoft","link":"https://github.com/microsoft/presidio","description":"toolset for detecting Personal Identifiable Information (PII) and other sensitive data in images and text","category":"Classification"},{"name":"Llama Guard by Meta","link":"https://github.com/meta-llama/PurpleLlama/tree/main/Llama-Guard3","description":"AI-powered content moderation model to detect harm in text-based interactions","category":"Classification"},{"name":"Purple Llama by Meta","link":"https://github.com/meta-llama/PurpleLlama/tree/main/Llama-Guard3","description":"set of tools to assess and improve LLM security. Includes Llama Guard, CyberSec Eval, and Code Shield","category":"Classification"},{"name":"ShieldGemma by Google DeepMind","link":"https://www.kaggle.com/code/fernandosr85/shieldgemma-web-content-safety-analyzer?scriptVersionId=198456916","description":"AI safety toolkit by Google DeepMind designed to help detect and mitigate harmful or unsafe outputs in LLM applications","category":"Classification"},{"name":"Roblox Voice Safety Classifier","link":"https://github.com/Roblox/voice-safety-classifier","description":"machine learnign model that detects and moderates harmful content in real-time voice chat on Roblox. Focuses on spoken language detection.","category":"Classification"},{"name":"Detoxify by Unitary AI","link":"https://github.com/unitaryai/detoxify","description":"detects and mitigates generalized toxic language (including hate speech, harassment, bullying) in text","category":"Classification"},{"name":"NSFW Filtering","link":"https://github.com/nsfw-filter/nsfw-filter","description":"browser extension to block explicit images from online platforms. User facing.","category":"Classification"},{"name":"NSFW Keras Model","link":"https://github.com/GantMan/nsfw_model","description":"convoluted neural network (CNN) based explicit image ML model","category":"Classification"},{"name":"Guardrails AI","link":"https://github.com/guardrails-ai/guardrails","description":"a Python framework that helps build safe AI applications checking input/output for predefined risks","category":"Classification"},{"name":"Mjolnir by Matrix","link":"https://github.com/matrix-org/mjolnir","description":"moderation bot for the Matrix protocol that automatically enforces content policies","category":"Core Infrastructure"},{"name":"AbuseIO","link":"https://github.com/AbuseIO/AbuseIO","description":"abuse management platform designed to help organizations handle and track abuse complaints related to online content, infrastructure, or services","category":"Core Infrastructure"},{"name":"Ozone by Bluesky","link":"https://github.com/bluesky-social/ozone","description":"labeling tool designed for Bluesky. Includes moderation features to action on abuse flags, policy enforcement tools, and investigation features","category":"Core Infrastructure"},{"name":"Open Truss by Github","link":"https://github.com/open-truss/open-truss","description":"framework designed to help users create internal tools without needing to write code","category":"Core Infrastructure"},{"name":"Access by Discord","link":"https://github.com/discord/access","description":"a centralized portal for managing access to internal systems within any organization","category":"Core Infrastructure"},{"name":"SpamAssassin by Apache","link":"https://spamassassin.apache.org","description":"anti-spam platform that uses a variety of techniques, including text analysis, Bayesian filtering, and DNS blocklists, to classify and block unsolicited email","category":"Clustering"},{"name":"scikit-learn","link":"https://github.com/scikit-learn/scikit-learn","description":"python library including clustering through various algorithms, such as K-Means, DBSCAN, and hierarchical clustering","category":"Clustering"},{"name":"RulesEngine by Microsoft","link":"https://microsoft.github.io/RulesEngine/","description":"a library for abstracting business logic, rules, and policies from a system via JSON  for .NET language families","category":"Rules Engines"},{"name":"Marble","link":"https://github.com/checkmarble/marble","description":"a real-time fraud detection and compliance engine tailored for fintech companies and financial institutions","category":"Rules Engines"},{"name":"Automod","link":"https://github.com/bluesky-social/indigo/tree/main/automod","description":"a tool for automating content moderation processes for the Bluesky social network and other apps on the AT Protocol","category":"Rules Engines"},{"name":"Wikimedia Smite Spam","link":"https://github.com/wikimedia/mediawiki-extensions-SmiteSpam","description":"an extension for MediaWiki that helps identify and manage spam content on a wiki","category":"Rules Engines"},{"name":"RabbitMQ","link":"https://github.com/rabbitmq","description":"a message broker that enables applications to communicate with each other by sending messages through queues","category":"Review"},{"name":"BullMQ","link":"https://github.com/taskforcesh/bullmq","description":"message queue and batch processing for NodeJS and Python based on Redis","category":"Review"},{"name":"Owlculus","link":"https://github.com/be0vlk/owlculus","description":"an OSINT (Open-Source Intelligence) toolkit and case management platform","category":"Review"},{"name":"NCMEC Reporting by ello","link":"https://github.com/ello/ncmec_reporting","description":"a Ruby client library for reporting incidents to the National Center for Missing & Exploited Children (NCMEC) CyberTipline","category":"Review"},{"name":"ThreatExchange by Meta","link":"https://github.com/facebook/ThreatExchange","description":"a platform that enables organizations to share information about  threats, such as malware, phishing attacks, and online safety harms in a structured and privacy-compliant manner","category":"Threat Intelligence"},{"name":"ThreatExchange Client via PHP","link":"https://github.com/certly/threatexchange","description":"a PHP client for ThreatExchange","category":"Threat Intelligence"},{"name":"ThreatExchange via Python","link":"https://github.com/facebook/ThreatExchange/tree/main/python-threatexchange","description":"a Python library for ThreatExchange","category":"Threat Intelligence"},{"name":"FediCheck","link":"https://about.iftas.org/activities/moderation-as-a-service/fedicheck/","description":"a web service designed to assist ActivityPub service providers, such as Mastodon servers","category":"Threat Intelligence"},{"name":"Aegis Content Safety by NVIDIA","link":"https://huggingface.co/datasets/nvidia/Aegis-AI-Content-Safety-Dataset-2.0","description":"a dataset created by NVIDIA to aid in content moderation and toxicity detection","category":"Datasets"},{"name":"Toxicity by Jigsaw","link":"https://huggingface.co/datasets/google/jigsaw_toxicity_pred","description":"a large number of Wikipedia comments which have been labeled by human raters for toxic behavior","category":"Datasets"}]